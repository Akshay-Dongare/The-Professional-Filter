{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to C:\\Users\\Akshay\n",
      "[nltk_data]    |     Dongare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allen-p/_sent_mail/1002.</td>\n",
       "      <td>Message-ID: &lt;30965995.1075863688265.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allen-p/_sent_mail/1003.</td>\n",
       "      <td>Message-ID: &lt;16254169.1075863688286.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allen-p/_sent_mail/1004.</td>\n",
       "      <td>Message-ID: &lt;17189699.1075863688308.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5026</th>\n",
       "      <td>arnold-j/deleted_items/163.</td>\n",
       "      <td>Message-ID: &lt;11958623.1075852694098.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>arnold-j/deleted_items/164.</td>\n",
       "      <td>Message-ID: &lt;31095424.1075852694121.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>arnold-j/deleted_items/165.</td>\n",
       "      <td>Message-ID: &lt;10513011.1075852694149.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>arnold-j/deleted_items/166.</td>\n",
       "      <td>Message-ID: &lt;28097519.1075852694172.JavaMail.e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>arnold-j/deleted_items/167.</td>\n",
       "      <td>Message-ID: &lt;23485243.1075852694195.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5028 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file  \\\n",
       "3        allen-p/_sent_mail/1000.   \n",
       "4        allen-p/_sent_mail/1001.   \n",
       "5        allen-p/_sent_mail/1002.   \n",
       "6        allen-p/_sent_mail/1003.   \n",
       "7        allen-p/_sent_mail/1004.   \n",
       "...                           ...   \n",
       "5026  arnold-j/deleted_items/163.   \n",
       "5027  arnold-j/deleted_items/164.   \n",
       "5028  arnold-j/deleted_items/165.   \n",
       "5029  arnold-j/deleted_items/166.   \n",
       "5030  arnold-j/deleted_items/167.   \n",
       "\n",
       "                                                message  label  \n",
       "3     Message-ID: <13505866.1075863688222.JavaMail.e...    1.0  \n",
       "4     Message-ID: <30922949.1075863688243.JavaMail.e...    1.0  \n",
       "5     Message-ID: <30965995.1075863688265.JavaMail.e...    1.0  \n",
       "6     Message-ID: <16254169.1075863688286.JavaMail.e...    1.0  \n",
       "7     Message-ID: <17189699.1075863688308.JavaMail.e...    1.0  \n",
       "...                                                 ...    ...  \n",
       "5026  Message-ID: <11958623.1075852694098.JavaMail.e...    1.0  \n",
       "5027  Message-ID: <31095424.1075852694121.JavaMail.e...    1.0  \n",
       "5028  Message-ID: <10513011.1075852694149.JavaMail.e...    1.0  \n",
       "5029  Message-ID: <28097519.1075852694172.JavaMail.e...    0.0  \n",
       "5030  Message-ID: <23485243.1075852694195.JavaMail.e...    1.0  \n",
       "\n",
       "[5028 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from email import parser\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('all')\n",
    "\n",
    "df = pd.read_csv('./data/labelled/labelled_enron_emails.csv')\n",
    "\n",
    "# removing root directory crawler values\n",
    "df = df.iloc[3:]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file       0\n",
       "message    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allen-p/_sent_mail/1002.</td>\n",
       "      <td>Message-ID: &lt;30965995.1075863688265.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allen-p/_sent_mail/1003.</td>\n",
       "      <td>Message-ID: &lt;16254169.1075863688286.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allen-p/_sent_mail/1004.</td>\n",
       "      <td>Message-ID: &lt;17189699.1075863688308.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5026</th>\n",
       "      <td>arnold-j/deleted_items/163.</td>\n",
       "      <td>Message-ID: &lt;11958623.1075852694098.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>arnold-j/deleted_items/164.</td>\n",
       "      <td>Message-ID: &lt;31095424.1075852694121.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>arnold-j/deleted_items/165.</td>\n",
       "      <td>Message-ID: &lt;10513011.1075852694149.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>arnold-j/deleted_items/166.</td>\n",
       "      <td>Message-ID: &lt;28097519.1075852694172.JavaMail.e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>arnold-j/deleted_items/167.</td>\n",
       "      <td>Message-ID: &lt;23485243.1075852694195.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5028 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file  \\\n",
       "3        allen-p/_sent_mail/1000.   \n",
       "4        allen-p/_sent_mail/1001.   \n",
       "5        allen-p/_sent_mail/1002.   \n",
       "6        allen-p/_sent_mail/1003.   \n",
       "7        allen-p/_sent_mail/1004.   \n",
       "...                           ...   \n",
       "5026  arnold-j/deleted_items/163.   \n",
       "5027  arnold-j/deleted_items/164.   \n",
       "5028  arnold-j/deleted_items/165.   \n",
       "5029  arnold-j/deleted_items/166.   \n",
       "5030  arnold-j/deleted_items/167.   \n",
       "\n",
       "                                                message  label  \n",
       "3     Message-ID: <13505866.1075863688222.JavaMail.e...    1.0  \n",
       "4     Message-ID: <30922949.1075863688243.JavaMail.e...    1.0  \n",
       "5     Message-ID: <30965995.1075863688265.JavaMail.e...    1.0  \n",
       "6     Message-ID: <16254169.1075863688286.JavaMail.e...    1.0  \n",
       "7     Message-ID: <17189699.1075863688308.JavaMail.e...    1.0  \n",
       "...                                                 ...    ...  \n",
       "5026  Message-ID: <11958623.1075852694098.JavaMail.e...    1.0  \n",
       "5027  Message-ID: <31095424.1075852694121.JavaMail.e...    1.0  \n",
       "5028  Message-ID: <10513011.1075852694149.JavaMail.e...    1.0  \n",
       "5029  Message-ID: <28097519.1075852694172.JavaMail.e...    0.0  \n",
       "5030  Message-ID: <23485243.1075852694195.JavaMail.e...    1.0  \n",
       "\n",
       "[5028 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(to_replace='None', value=np.nan).dropna()\n",
    "df = df.astype(str)\n",
    "\n",
    "# s = pd.Series(df['EmailContent'])\n",
    "# s = s.convert_dtypes(convert_string=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file       object\n",
       "message    object\n",
       "label      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file       0\n",
       "message    0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(email_content):\n",
    "    features = {}\n",
    "    email_parser = parser.Parser()\n",
    "    \n",
    "    try:\n",
    "        email = email_parser.parsestr(email_content)\n",
    "\n",
    "        # 1. Subject of email\n",
    "        features['subject'] = email['subject']\n",
    "\n",
    "        # 2. No. of receivers including CC and BCC\n",
    "        receivers = []\n",
    "        for field in ['to', 'cc', 'bcc']:\n",
    "            if email[field]:\n",
    "                receivers.extend(re.findall(r'[\\w\\.-]+@[\\w\\.-]+', email[field]))\n",
    "        features['num_receivers'] = len(receivers)\n",
    "\n",
    "         # 3. Length of email\n",
    "        body = email.get_payload()\n",
    "        if email.is_multipart():\n",
    "            body = ''.join(part.get_payload(decode=True).decode() for part in email.get_payload() if isinstance(part.get_payload(), str))\n",
    "        features['length_of_email'] = len(body)\n",
    "\n",
    "        # 4. Email domain name\n",
    "        from_match = re.search(r'[\\w\\.-]+@([\\w\\.-]+)', email['from'])\n",
    "        features['email_domain'] = from_match.group(1) if from_match else None\n",
    "\n",
    "        # 6. Sent time\n",
    "        features['sent_time'] = email['date']\n",
    "\n",
    "        # 7. Whether the email is forwarded one or not\n",
    "        features['is_forwarded'] = 1 if (('fwd:' in email['subject'].lower()) or ('fw' in email['subject'].lower())) else 0\n",
    "\n",
    "        # 8. Sender's email address\n",
    "        sender_match = re.search(r'([\\w\\.-]+@[\\w\\.-]+)', email['from'])\n",
    "        features['sender_email'] = sender_match.group(1) if sender_match else None\n",
    "\n",
    "        # # NLP-related semantic features\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = word_tokenize(body.lower())\n",
    "        filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "        # 10. Unique word count (excluding stop words)\n",
    "        features['email_length'] = len(filtered_words)\n",
    "    \n",
    "    except:\n",
    "        # print(email_content)\n",
    "        features['subject'] = np.nan\n",
    "        features['num_receivers'] = np.nan\n",
    "        features['email_length'] = np.nan\n",
    "        features['email_domain'] = np.nan\n",
    "        features['sent_time'] = np.nan\n",
    "        features['is_forwarded'] = np.nan\n",
    "        features['sender_email'] = np.nan\n",
    "\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file             0\n",
       "message          0\n",
       "label            0\n",
       "sender_email     0\n",
       "subject          0\n",
       "num_receivers    0\n",
       "email_length     0\n",
       "email_domain     0\n",
       "sent_time        0\n",
       "is_forwarded     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_features = df['message'].apply(parse_email)\n",
    "\n",
    "# Create new columns in the dataframe with the extracted features\n",
    "for feature in ['sender_email', 'subject', 'num_receivers', 'email_length', 'email_domain', 'sent_time', 'is_forwarded']:\n",
    "    df[feature] = parsed_features.apply(lambda x: x[feature])\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file             0\n",
       "message          0\n",
       "label            0\n",
       "sender_email     0\n",
       "subject          0\n",
       "num_receivers    0\n",
       "email_length     0\n",
       "email_domain     0\n",
       "sent_time        0\n",
       "is_forwarded     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis=0, subset=['email_length', 'email_domain'])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>sender_email</th>\n",
       "      <th>subject</th>\n",
       "      <th>num_receivers</th>\n",
       "      <th>email_length</th>\n",
       "      <th>email_domain</th>\n",
       "      <th>sent_time</th>\n",
       "      <th>is_forwarded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allen-p/_sent_mail/1002.</td>\n",
       "      <td>Message-ID: &lt;30965995.1075863688265.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>Thu, 31 Aug 2000 04:17:00 -0700 (PDT)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allen-p/_sent_mail/1003.</td>\n",
       "      <td>Message-ID: &lt;16254169.1075863688286.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>Tue, 22 Aug 2000 07:44:00 -0700 (PDT)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allen-p/_sent_mail/1004.</td>\n",
       "      <td>Message-ID: &lt;17189699.1075863688308.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>Re: PRC review - phone calls</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>Fri, 14 Jul 2000 06:59:00 -0700 (PDT)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5026</th>\n",
       "      <td>arnold-j/deleted_items/163.</td>\n",
       "      <td>Message-ID: &lt;11958623.1075852694098.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>Telephone Interviews: Trading Track</td>\n",
       "      <td>16</td>\n",
       "      <td>69</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>Wed, 10 Oct 2001 12:53:27 -0700 (PDT)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>arnold-j/deleted_items/164.</td>\n",
       "      <td>Message-ID: &lt;31095424.1075852694121.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a..shankman@enron.com</td>\n",
       "      <td>RE:</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>Wed, 10 Oct 2001 13:13:05 -0700 (PDT)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>arnold-j/deleted_items/165.</td>\n",
       "      <td>Message-ID: &lt;10513011.1075852694149.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>ENA Trading Track - Interviews October</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>Wed, 10 Oct 2001 12:17:23 -0700 (PDT)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>arnold-j/deleted_items/166.</td>\n",
       "      <td>Message-ID: &lt;28097519.1075852694172.JavaMail.e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>margaret.allen@enron.com</td>\n",
       "      <td>THANKS!</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>Wed, 10 Oct 2001 09:00:39 -0700 (PDT)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>arnold-j/deleted_items/167.</td>\n",
       "      <td>Message-ID: &lt;23485243.1075852694195.JavaMail.e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ricky.collier@enron.com</td>\n",
       "      <td>Follow up for Hardware Request....</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>Wed, 10 Oct 2001 08:41:12 -0700 (PDT)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5028 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file  \\\n",
       "3        allen-p/_sent_mail/1000.   \n",
       "4        allen-p/_sent_mail/1001.   \n",
       "5        allen-p/_sent_mail/1002.   \n",
       "6        allen-p/_sent_mail/1003.   \n",
       "7        allen-p/_sent_mail/1004.   \n",
       "...                           ...   \n",
       "5026  arnold-j/deleted_items/163.   \n",
       "5027  arnold-j/deleted_items/164.   \n",
       "5028  arnold-j/deleted_items/165.   \n",
       "5029  arnold-j/deleted_items/166.   \n",
       "5030  arnold-j/deleted_items/167.   \n",
       "\n",
       "                                                message label  \\\n",
       "3     Message-ID: <13505866.1075863688222.JavaMail.e...   1.0   \n",
       "4     Message-ID: <30922949.1075863688243.JavaMail.e...   1.0   \n",
       "5     Message-ID: <30965995.1075863688265.JavaMail.e...   1.0   \n",
       "6     Message-ID: <16254169.1075863688286.JavaMail.e...   1.0   \n",
       "7     Message-ID: <17189699.1075863688308.JavaMail.e...   1.0   \n",
       "...                                                 ...   ...   \n",
       "5026  Message-ID: <11958623.1075852694098.JavaMail.e...   1.0   \n",
       "5027  Message-ID: <31095424.1075852694121.JavaMail.e...   1.0   \n",
       "5028  Message-ID: <10513011.1075852694149.JavaMail.e...   1.0   \n",
       "5029  Message-ID: <28097519.1075852694172.JavaMail.e...   0.0   \n",
       "5030  Message-ID: <23485243.1075852694195.JavaMail.e...   1.0   \n",
       "\n",
       "                  sender_email                                 subject  \\\n",
       "3      phillip.allen@enron.com                                           \n",
       "4      phillip.allen@enron.com                               Re: Hello   \n",
       "5      phillip.allen@enron.com                               Re: Hello   \n",
       "6      phillip.allen@enron.com                                           \n",
       "7      phillip.allen@enron.com            Re: PRC review - phone calls   \n",
       "...                        ...                                     ...   \n",
       "5026   karen.buckley@enron.com     Telephone Interviews: Trading Track   \n",
       "5027     a..shankman@enron.com                                     RE:   \n",
       "5028   karen.buckley@enron.com  ENA Trading Track - Interviews October   \n",
       "5029  margaret.allen@enron.com                                 THANKS!   \n",
       "5030   ricky.collier@enron.com      Follow up for Hardware Request....   \n",
       "\n",
       "      num_receivers  email_length email_domain  \\\n",
       "3                 1            16    enron.com   \n",
       "4                 1             3    enron.com   \n",
       "5                 1             6    enron.com   \n",
       "6                 2            24    enron.com   \n",
       "7                 1             2    enron.com   \n",
       "...             ...           ...          ...   \n",
       "5026             16            69    enron.com   \n",
       "5027              1            69    enron.com   \n",
       "5028             33            45    enron.com   \n",
       "5029              1            25    enron.com   \n",
       "5030              1            11    enron.com   \n",
       "\n",
       "                                  sent_time  is_forwarded  \n",
       "3     Mon, 23 Oct 2000 06:13:00 -0700 (PDT)             0  \n",
       "4     Thu, 31 Aug 2000 05:07:00 -0700 (PDT)             0  \n",
       "5     Thu, 31 Aug 2000 04:17:00 -0700 (PDT)             0  \n",
       "6     Tue, 22 Aug 2000 07:44:00 -0700 (PDT)             0  \n",
       "7     Fri, 14 Jul 2000 06:59:00 -0700 (PDT)             0  \n",
       "...                                     ...           ...  \n",
       "5026  Wed, 10 Oct 2001 12:53:27 -0700 (PDT)             0  \n",
       "5027  Wed, 10 Oct 2001 13:13:05 -0700 (PDT)             0  \n",
       "5028  Wed, 10 Oct 2001 12:17:23 -0700 (PDT)             0  \n",
       "5029  Wed, 10 Oct 2001 09:00:39 -0700 (PDT)             0  \n",
       "5030  Wed, 10 Oct 2001 08:41:12 -0700 (PDT)             0  \n",
       "\n",
       "[5028 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataframe to a new CSV file\n",
    "df.to_csv('./data/parsed/parsed_emails.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
